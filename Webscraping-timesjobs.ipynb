{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Multiple Pages Of Job-seeking Website timesjobs.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make empty lists that serve as the intitial storage for the scraped info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names = []\n",
    "skills = []\n",
    "work_exp = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the work begins.\n",
    "The job of the following piece of code is to :\n",
    "* Go to the website of choice\n",
    "* Loop through the first 25 pages(although it can be easily set to go through all the pages).\n",
    "* Parse the HTML code of those said pages\n",
    "* Extract any kind of information ; here, Company name, Skills required and Work experience required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1='https://www.timesjobs.com/candidate/job-search.html?from=submit&actualTxtKeywords=python&searchBy=0&rdoOperator=OR&searchType=personalizedSearch&luceneResultSize=25&postWeek=60&txtKeywords=python&pDate=I&sequence= &startPage= '\n",
    "for i in range (0,25):\n",
    "    url = url1.replace(' ', str(i))\n",
    "    browser_page=requests.get(url)\n",
    "    src=browser_page.content\n",
    "    soup=BeautifulSoup(src,'lxml')\n",
    "    jobs=soup.find_all('li', class_=\"clearfix job-bx wht-shd-bx\")\n",
    "    \n",
    "    for job in jobs:\n",
    "        company_name=job.find('h3', class_=\"joblist-comp-name\").text.strip()\n",
    "        skill=job.find('span', class_=\"srp-skills\").text.strip()\n",
    "        work_ex = job.find('li').text.strip().replace('card_travel','')\n",
    "         \n",
    "        company_names.append(company_name)\n",
    "        skills.append(skill)\n",
    "        work_exp.append(work_ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we tabulate all our recently acquired data by first creating a python dictionary which we then use to create our Pandas dataframe,'dict_df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Work experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surya Informatics Solutions Pvt. Ltd.</td>\n",
       "      <td>python  ,  web technologies  ,  linux  ,  mobi...</td>\n",
       "      <td>0 - 3 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capgemini</td>\n",
       "      <td>security compliance  ,  python  ,  html5  ,  m...</td>\n",
       "      <td>12 - 15 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pure Tech Codex Private Limited</td>\n",
       "      <td>rest  ,  python  ,  database  ,  django  ,  de...</td>\n",
       "      <td>2 - 3 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gemini Solutions</td>\n",
       "      <td>python  ,  mobile  ,  svn  ,  nosql  ,  python...</td>\n",
       "      <td>4 - 7 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEMINI SOFTWARE SOLUTIONS</td>\n",
       "      <td>python  ,  mobile  ,  svn  ,  nosql  ,  python...</td>\n",
       "      <td>4 - 7 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Binance</td>\n",
       "      <td>python  ,  oracle  ,  ubuntu  ,  senior softwa...</td>\n",
       "      <td>5 - 8 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Arete Careers  ( OPC )  Pvt Ltd</td>\n",
       "      <td>rest  ,  python  ,  rdbms  ,  lucene  ,  probl...</td>\n",
       "      <td>3 - 6 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Red Bixbite Solutions Pvt. Ltd.</td>\n",
       "      <td>fundamentals  ,  html5  ,  storage  ,  oop  , ...</td>\n",
       "      <td>3 - 6 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Draup</td>\n",
       "      <td>python  ,  node.js  ,  information retrieval  ...</td>\n",
       "      <td>3 - 5 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Symphisys</td>\n",
       "      <td>sql  ,  git  ,  xml  ,  linux  ,  json  ,  mys...</td>\n",
       "      <td>5 - 10 yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Company  \\\n",
       "0    Surya Informatics Solutions Pvt. Ltd.   \n",
       "1                                capgemini   \n",
       "2          Pure Tech Codex Private Limited   \n",
       "3                         Gemini Solutions   \n",
       "4                GEMINI SOFTWARE SOLUTIONS   \n",
       "..                                     ...   \n",
       "595                                Binance   \n",
       "596        Arete Careers  ( OPC )  Pvt Ltd   \n",
       "597        Red Bixbite Solutions Pvt. Ltd.   \n",
       "598                                  Draup   \n",
       "599                              Symphisys   \n",
       "\n",
       "                                                Skills Work experience  \n",
       "0    python  ,  web technologies  ,  linux  ,  mobi...       0 - 3 yrs  \n",
       "1    security compliance  ,  python  ,  html5  ,  m...     12 - 15 yrs  \n",
       "2    rest  ,  python  ,  database  ,  django  ,  de...       2 - 3 yrs  \n",
       "3    python  ,  mobile  ,  svn  ,  nosql  ,  python...       4 - 7 yrs  \n",
       "4    python  ,  mobile  ,  svn  ,  nosql  ,  python...       4 - 7 yrs  \n",
       "..                                                 ...             ...  \n",
       "595  python  ,  oracle  ,  ubuntu  ,  senior softwa...       5 - 8 yrs  \n",
       "596  rest  ,  python  ,  rdbms  ,  lucene  ,  probl...       3 - 6 yrs  \n",
       "597  fundamentals  ,  html5  ,  storage  ,  oop  , ...       3 - 6 yrs  \n",
       "598  python  ,  node.js  ,  information retrieval  ...       3 - 5 yrs  \n",
       "599  sql  ,  git  ,  xml  ,  linux  ,  json  ,  mys...      5 - 10 yrs  \n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_info = {'Company': company_names,\n",
    "            'Skills': skills,\n",
    "            'Work experience': work_exp}\n",
    "dict_df = pd.DataFrame.from_dict(dict_info)\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save our 600 rows of data(21492,if we had chosen to scrape all the Python job-pages) and save it in the Desktop folder of our local machine,thus finishing the job at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df.to_csv('tjobs.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
